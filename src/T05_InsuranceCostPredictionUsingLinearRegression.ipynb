{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0c02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6cd71",
   "metadata": {},
   "source": [
    "# Downloading The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421258d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./dataset\\T05_Insurance.csv\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = \"https://gist.github.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n",
    "DATA_FILENAME = \"T05_Insurance.csv\"\n",
    "download_url(DATASET_URL, './dataset', DATA_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea949d8c",
   "metadata": {},
   "source": [
    "using pandas to read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e7956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e6752",
   "metadata": {},
   "source": [
    "Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015d23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/T05_Insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a1c7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf65f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8e2573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b0e0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) # way to take out the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18f1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3698e310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d98f48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab1e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b76b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no use to know the region, as the insurance won't depened on region, it's depend on health\n",
    "dataset.drop([\"region\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e76972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker      charges\n",
       "0      19  female  27.900         0    yes  16884.92400\n",
       "1      18    male  33.770         1     no   1725.55230\n",
       "2      28    male  33.000         3     no   4449.46200\n",
       "3      33    male  22.705         0     no  21984.47061\n",
       "4      32    male  28.880         0     no   3866.85520\n",
       "...   ...     ...     ...       ...    ...          ...\n",
       "1333   50    male  30.970         3     no  10600.54830\n",
       "1334   18  female  31.920         0     no   2205.98080\n",
       "1335   18  female  36.850         0     no   1629.83350\n",
       "1336   21  female  25.800         0     no   2007.94500\n",
       "1337   61  female  29.070         0    yes  29141.36030\n",
       "\n",
       "[1338 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset # now our main dataset got change, as we have used inplace=True while droping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2e65f",
   "metadata": {},
   "source": [
    "One Hot Encoding For Cotegorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60eb1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"sex\", \"smoker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f517fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = [\"charges\"]\n",
    "input_cols = [\"age\", \"sex\", \"bmi\", \"children\", \"smoker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6119c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    for col in categorical_cols: # this is ordinal encoding\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array\n",
    "# doing ordinal encoding here, will not matter, bcz the categorical data we have is of two categories only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dbe569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1338, 5), (1338, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataset)\n",
    "inputs_array.shape, targets_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "953ab770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[19.  ,  0.  , 27.9 ,  0.  ,  1.  ],\n",
       "        [18.  ,  1.  , 33.77,  1.  ,  0.  ],\n",
       "        [28.  ,  1.  , 33.  ,  3.  ,  0.  ],\n",
       "        ...,\n",
       "        [18.  ,  0.  , 36.85,  0.  ,  0.  ],\n",
       "        [21.  ,  0.  , 25.8 ,  0.  ,  0.  ],\n",
       "        [61.  ,  0.  , 29.07,  0.  ,  1.  ]]),\n",
       " array([[16884.924 ],\n",
       "        [ 1725.5523],\n",
       "        [ 4449.462 ],\n",
       "        ...,\n",
       "        [ 1629.8335],\n",
       "        [ 2007.945 ],\n",
       "        [29141.3603]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8e13a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array.dtype, targets_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c25ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs_array), type(targets_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91230e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcccf35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[19.  ,  0.  , 27.9 ,  0.  ,  1.  ],\n",
       "        [18.  ,  1.  , 33.77,  1.  ,  0.  ],\n",
       "        [28.  ,  1.  , 33.  ,  3.  ,  0.  ],\n",
       "        ...,\n",
       "        [18.  ,  0.  , 36.85,  0.  ,  0.  ],\n",
       "        [21.  ,  0.  , 25.8 ,  0.  ,  0.  ],\n",
       "        [61.  ,  0.  , 29.07,  0.  ,  1.  ]]),\n",
       " array([[16884.924 ],\n",
       "        [ 1725.5523],\n",
       "        [ 4449.462 ],\n",
       "        ...,\n",
       "        [ 1629.8335],\n",
       "        [ 2007.945 ],\n",
       "        [29141.3603]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_array, targets_array = dataframe_to_arrays(dataset)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae28ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9860cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(inputs_array)\n",
    "targets = torch.tensor(targets_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "719973eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype, targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d904530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ed75208",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ec870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = random_split(dataset, [1200, 138])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c80055d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d04853d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[30.0000,  0.0000, 30.9000,  3.0000,  0.0000],\n",
      "        [33.0000,  0.0000, 26.6950,  0.0000,  0.0000],\n",
      "        [29.0000,  0.0000, 21.8500,  0.0000,  1.0000],\n",
      "        [35.0000,  1.0000, 36.6700,  1.0000,  1.0000],\n",
      "        [53.0000,  1.0000, 31.3500,  0.0000,  0.0000],\n",
      "        [29.0000,  1.0000, 27.9400,  0.0000,  0.0000],\n",
      "        [28.0000,  0.0000, 17.2900,  0.0000,  0.0000],\n",
      "        [58.0000,  0.0000, 41.9100,  0.0000,  0.0000],\n",
      "        [29.0000,  0.0000, 29.5900,  1.0000,  0.0000],\n",
      "        [55.0000,  0.0000, 33.5350,  2.0000,  0.0000],\n",
      "        [26.0000,  0.0000, 19.8000,  1.0000,  0.0000],\n",
      "        [49.0000,  1.0000, 25.8400,  2.0000,  1.0000],\n",
      "        [45.0000,  1.0000, 27.5000,  3.0000,  0.0000],\n",
      "        [64.0000,  0.0000, 32.9650,  0.0000,  0.0000],\n",
      "        [64.0000,  0.0000, 31.3000,  2.0000,  1.0000]], dtype=torch.float64)\n",
      "targets: tensor([[ 5325.6510],\n",
      "        [ 4571.4131],\n",
      "        [16115.3045],\n",
      "        [39774.2763],\n",
      "        [27346.0421],\n",
      "        [ 2867.1196],\n",
      "        [ 3732.6251],\n",
      "        [24227.3372],\n",
      "        [ 3947.4131],\n",
      "        [12269.6887],\n",
      "        [ 3378.9100],\n",
      "        [23807.2406],\n",
      "        [ 8615.3000],\n",
      "        [14692.6694],\n",
      "        [47291.0550]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"inputs:\", xb)\n",
    "    print(\"targets:\", yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2870aa",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6ee85",
   "metadata": {},
   "source": [
    "Importing linear function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecff7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98b48b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ff04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of using mse loss, we are using rms loss, its bcz to find the local minima of gradient descent of mse loss is\n",
    "# a difficult task. Using mse loss make the loss fluctuate about a point, loss will not get dcrease\n",
    "class InsuranceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(5, 1)\n",
    "        self.history = []\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        return self.linear(inputs)\n",
    "    \n",
    "    def lossCal(self, batch):\n",
    "        inputs, targets = batch\n",
    "        pred = self.prediction(inputs)\n",
    "        mse = F.mse_loss(pred, targets)\n",
    "        loss = torch.sqrt(mse)\n",
    "#         losslist.append(loss.item()) # this is used to add loss in a list, to plot the loss graph\n",
    "#         loss = F.l1_loss(pred, targets)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch): # this will be given at validation phase.\n",
    "        inputs, targets = batch\n",
    "        loss = self.lossCal(batch)\n",
    "        return {'val_loss': loss.detach()}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def evaluate(self, val_loader):\n",
    "        outputs = [self.validation_step(batch) for batch in val_loader]\n",
    "        return self.validation_epoch_end(outputs)\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss']))\n",
    "        \n",
    "    \n",
    "    def training_(self, epochs, lr, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "        optimizer = opt_func(self.linear.parameters(), lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # training phase\n",
    "            for batch in train_loader:\n",
    "                loss = self.lossCal(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            \n",
    "            # validation phase\n",
    "            result = self.evaluate(val_loader)\n",
    "            self.epoch_end(epoch, result)\n",
    "            self.history.append(result)\n",
    "        \n",
    "#         return self.history     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe53a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InsuranceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1a31228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4403,  0.0330,  0.3729,  0.1580,  0.1546]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3834], requires_grad=True)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c85f7aeb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 13245.0779\n",
      "Epoch [1], val_loss: 13366.9315\n",
      "Epoch [2], val_loss: 13488.0801\n",
      "Epoch [3], val_loss: 13430.5541\n",
      "Epoch [4], val_loss: 13162.4338\n",
      "Epoch [5], val_loss: 13362.8523\n",
      "Epoch [6], val_loss: 13613.5186\n",
      "Epoch [7], val_loss: 13483.6953\n",
      "Epoch [8], val_loss: 13448.7539\n",
      "Epoch [9], val_loss: 13153.9904\n",
      "Epoch [10], val_loss: 13132.9497\n",
      "Epoch [11], val_loss: 13283.2450\n",
      "Epoch [12], val_loss: 13279.2728\n",
      "Epoch [13], val_loss: 13743.9071\n",
      "Epoch [14], val_loss: 13116.0978\n",
      "Epoch [15], val_loss: 13149.4132\n",
      "Epoch [16], val_loss: 13053.2717\n",
      "Epoch [17], val_loss: 13055.8916\n",
      "Epoch [18], val_loss: 13280.5718\n",
      "Epoch [19], val_loss: 13430.1532\n",
      "Epoch [20], val_loss: 13026.6002\n",
      "Epoch [21], val_loss: 13052.7490\n",
      "Epoch [22], val_loss: 13173.3155\n",
      "Epoch [23], val_loss: 13089.2434\n",
      "Epoch [24], val_loss: 13075.2081\n",
      "Epoch [25], val_loss: 13364.6291\n",
      "Epoch [26], val_loss: 13153.7490\n",
      "Epoch [27], val_loss: 13048.7185\n",
      "Epoch [28], val_loss: 13017.7743\n",
      "Epoch [29], val_loss: 13019.1875\n",
      "Epoch [30], val_loss: 13051.0918\n",
      "Epoch [31], val_loss: 12968.3775\n",
      "Epoch [32], val_loss: 14003.4613\n",
      "Epoch [33], val_loss: 12944.1354\n",
      "Epoch [34], val_loss: 12860.6022\n",
      "Epoch [35], val_loss: 12959.9524\n",
      "Epoch [36], val_loss: 12991.4947\n",
      "Epoch [37], val_loss: 13075.8263\n",
      "Epoch [38], val_loss: 13993.7990\n",
      "Epoch [39], val_loss: 13066.2402\n",
      "Epoch [40], val_loss: 12865.0701\n",
      "Epoch [41], val_loss: 13003.6536\n",
      "Epoch [42], val_loss: 12978.7883\n",
      "Epoch [43], val_loss: 12987.1057\n",
      "Epoch [44], val_loss: 13026.3616\n",
      "Epoch [45], val_loss: 12974.4689\n",
      "Epoch [46], val_loss: 12885.6015\n",
      "Epoch [47], val_loss: 12881.9896\n",
      "Epoch [48], val_loss: 12818.1688\n",
      "Epoch [49], val_loss: 12854.9105\n",
      "Epoch [50], val_loss: 12905.3920\n",
      "Epoch [51], val_loss: 13339.8955\n",
      "Epoch [52], val_loss: 13007.9294\n",
      "Epoch [53], val_loss: 12683.0581\n",
      "Epoch [54], val_loss: 12667.8184\n",
      "Epoch [55], val_loss: 12722.4653\n",
      "Epoch [56], val_loss: 12778.2049\n",
      "Epoch [57], val_loss: 12763.2728\n",
      "Epoch [58], val_loss: 12702.5377\n",
      "Epoch [59], val_loss: 12797.0051\n",
      "Epoch [60], val_loss: 13243.0560\n",
      "Epoch [61], val_loss: 12735.7664\n",
      "Epoch [62], val_loss: 12587.7097\n",
      "Epoch [63], val_loss: 12742.7652\n",
      "Epoch [64], val_loss: 12578.4389\n",
      "Epoch [65], val_loss: 12734.3445\n",
      "Epoch [66], val_loss: 12577.7449\n",
      "Epoch [67], val_loss: 12756.2634\n",
      "Epoch [68], val_loss: 12847.2551\n",
      "Epoch [69], val_loss: 12570.2099\n",
      "Epoch [70], val_loss: 12506.7574\n",
      "Epoch [71], val_loss: 12511.8402\n",
      "Epoch [72], val_loss: 12701.3457\n",
      "Epoch [73], val_loss: 12710.0106\n",
      "Epoch [74], val_loss: 12467.8614\n",
      "Epoch [75], val_loss: 12591.1680\n",
      "Epoch [76], val_loss: 12633.1089\n",
      "Epoch [77], val_loss: 12478.8424\n",
      "Epoch [78], val_loss: 12608.1186\n",
      "Epoch [79], val_loss: 12477.6763\n",
      "Epoch [80], val_loss: 12412.6144\n",
      "Epoch [81], val_loss: 12457.7142\n",
      "Epoch [82], val_loss: 12868.3486\n",
      "Epoch [83], val_loss: 12390.4040\n",
      "Epoch [84], val_loss: 12433.9905\n",
      "Epoch [85], val_loss: 12771.1191\n",
      "Epoch [86], val_loss: 12445.3937\n",
      "Epoch [87], val_loss: 12380.9891\n",
      "Epoch [88], val_loss: 12446.4653\n",
      "Epoch [89], val_loss: 12670.6281\n",
      "Epoch [90], val_loss: 12316.8203\n",
      "Epoch [91], val_loss: 12762.2071\n",
      "Epoch [92], val_loss: 12314.8787\n",
      "Epoch [93], val_loss: 12353.3965\n",
      "Epoch [94], val_loss: 12325.4592\n",
      "Epoch [95], val_loss: 12339.5462\n",
      "Epoch [96], val_loss: 12574.1344\n",
      "Epoch [97], val_loss: 12372.1784\n",
      "Epoch [98], val_loss: 12543.2698\n",
      "Epoch [99], val_loss: 12226.2636\n",
      "Epoch [100], val_loss: 12481.9966\n",
      "Epoch [101], val_loss: 12257.3073\n",
      "Epoch [102], val_loss: 12227.0411\n",
      "Epoch [103], val_loss: 12299.6988\n",
      "Epoch [104], val_loss: 12210.1190\n",
      "Epoch [105], val_loss: 12197.8969\n",
      "Epoch [106], val_loss: 12317.3859\n",
      "Epoch [107], val_loss: 12168.3122\n",
      "Epoch [108], val_loss: 12634.3452\n",
      "Epoch [109], val_loss: 12311.8001\n",
      "Epoch [110], val_loss: 12428.7023\n",
      "Epoch [111], val_loss: 12432.1550\n",
      "Epoch [112], val_loss: 12260.0889\n",
      "Epoch [113], val_loss: 12213.2717\n",
      "Epoch [114], val_loss: 12405.5915\n",
      "Epoch [115], val_loss: 12259.5739\n",
      "Epoch [116], val_loss: 12352.2062\n",
      "Epoch [117], val_loss: 12079.2310\n",
      "Epoch [118], val_loss: 12099.0484\n",
      "Epoch [119], val_loss: 12285.6678\n",
      "Epoch [120], val_loss: 12187.2379\n",
      "Epoch [121], val_loss: 12312.4767\n",
      "Epoch [122], val_loss: 12491.0035\n",
      "Epoch [123], val_loss: 12347.7778\n",
      "Epoch [124], val_loss: 12331.2727\n",
      "Epoch [125], val_loss: 12219.8507\n",
      "Epoch [126], val_loss: 12077.0351\n",
      "Epoch [127], val_loss: 12115.2650\n",
      "Epoch [128], val_loss: 11989.3279\n",
      "Epoch [129], val_loss: 12331.9272\n",
      "Epoch [130], val_loss: 12958.3605\n",
      "Epoch [131], val_loss: 11947.9457\n",
      "Epoch [132], val_loss: 11945.6307\n",
      "Epoch [133], val_loss: 12185.9502\n",
      "Epoch [134], val_loss: 12191.4181\n",
      "Epoch [135], val_loss: 11910.7218\n",
      "Epoch [136], val_loss: 12243.5533\n",
      "Epoch [137], val_loss: 11944.1131\n",
      "Epoch [138], val_loss: 12497.0488\n",
      "Epoch [139], val_loss: 11930.9254\n",
      "Epoch [140], val_loss: 12315.3608\n",
      "Epoch [141], val_loss: 12169.3367\n",
      "Epoch [142], val_loss: 12122.2406\n",
      "Epoch [143], val_loss: 12147.5705\n",
      "Epoch [144], val_loss: 11832.1621\n",
      "Epoch [145], val_loss: 11910.7241\n",
      "Epoch [146], val_loss: 11965.5665\n",
      "Epoch [147], val_loss: 11860.9252\n",
      "Epoch [148], val_loss: 11857.8560\n",
      "Epoch [149], val_loss: 11813.4442\n",
      "Epoch [150], val_loss: 11971.9274\n",
      "Epoch [151], val_loss: 11879.9480\n",
      "Epoch [152], val_loss: 11855.1789\n",
      "Epoch [153], val_loss: 12142.3233\n",
      "Epoch [154], val_loss: 11898.7814\n",
      "Epoch [155], val_loss: 11821.2426\n",
      "Epoch [156], val_loss: 11711.6424\n",
      "Epoch [157], val_loss: 11769.8628\n",
      "Epoch [158], val_loss: 11884.5679\n",
      "Epoch [159], val_loss: 12210.0988\n",
      "Epoch [160], val_loss: 12125.3029\n",
      "Epoch [161], val_loss: 11673.2936\n",
      "Epoch [162], val_loss: 11677.4492\n",
      "Epoch [163], val_loss: 11659.0292\n",
      "Epoch [164], val_loss: 11975.0622\n",
      "Epoch [165], val_loss: 11836.0821\n",
      "Epoch [166], val_loss: 11847.5294\n",
      "Epoch [167], val_loss: 11777.5255\n",
      "Epoch [168], val_loss: 12036.6085\n",
      "Epoch [169], val_loss: 11898.3132\n",
      "Epoch [170], val_loss: 11651.0281\n",
      "Epoch [171], val_loss: 12454.2714\n",
      "Epoch [172], val_loss: 11570.2401\n",
      "Epoch [173], val_loss: 11834.9104\n",
      "Epoch [174], val_loss: 12269.7831\n",
      "Epoch [175], val_loss: 11669.4525\n",
      "Epoch [176], val_loss: 11582.8097\n",
      "Epoch [177], val_loss: 11773.1677\n",
      "Epoch [178], val_loss: 11535.9600\n",
      "Epoch [179], val_loss: 11809.6847\n",
      "Epoch [180], val_loss: 11587.3371\n",
      "Epoch [181], val_loss: 11571.8240\n",
      "Epoch [182], val_loss: 11578.3576\n",
      "Epoch [183], val_loss: 11648.1942\n",
      "Epoch [184], val_loss: 11549.6881\n",
      "Epoch [185], val_loss: 11571.2786\n",
      "Epoch [186], val_loss: 11595.6965\n",
      "Epoch [187], val_loss: 11532.4429\n",
      "Epoch [188], val_loss: 11579.8928\n",
      "Epoch [189], val_loss: 11485.9463\n",
      "Epoch [190], val_loss: 11768.8608\n",
      "Epoch [191], val_loss: 11557.0590\n",
      "Epoch [192], val_loss: 11411.0161\n",
      "Epoch [193], val_loss: 11426.2280\n",
      "Epoch [194], val_loss: 11876.9663\n",
      "Epoch [195], val_loss: 11591.7083\n",
      "Epoch [196], val_loss: 11462.7794\n",
      "Epoch [197], val_loss: 11472.8843\n",
      "Epoch [198], val_loss: 11346.0852\n",
      "Epoch [199], val_loss: 11586.3182\n",
      "Epoch [200], val_loss: 11389.9840\n",
      "Epoch [201], val_loss: 11513.4017\n",
      "Epoch [202], val_loss: 11517.3697\n",
      "Epoch [203], val_loss: 11385.4858\n",
      "Epoch [204], val_loss: 11510.6243\n",
      "Epoch [205], val_loss: 11570.7073\n",
      "Epoch [206], val_loss: 11472.4382\n",
      "Epoch [207], val_loss: 11294.6501\n",
      "Epoch [208], val_loss: 11277.5352\n",
      "Epoch [209], val_loss: 11486.1663\n",
      "Epoch [210], val_loss: 11780.6005\n",
      "Epoch [211], val_loss: 11268.0502\n",
      "Epoch [212], val_loss: 11312.6898\n",
      "Epoch [213], val_loss: 11791.5285\n",
      "Epoch [214], val_loss: 11408.0979\n",
      "Epoch [215], val_loss: 11259.7684\n",
      "Epoch [216], val_loss: 11205.1005\n",
      "Epoch [217], val_loss: 11458.9402\n",
      "Epoch [218], val_loss: 11438.1159\n",
      "Epoch [219], val_loss: 11224.2053\n",
      "Epoch [220], val_loss: 11610.8373\n",
      "Epoch [221], val_loss: 11598.8048\n",
      "Epoch [222], val_loss: 11238.5898\n",
      "Epoch [223], val_loss: 11308.2961\n",
      "Epoch [224], val_loss: 11217.4744\n",
      "Epoch [225], val_loss: 11482.6690\n",
      "Epoch [226], val_loss: 11130.9899\n",
      "Epoch [227], val_loss: 11118.7113\n",
      "Epoch [228], val_loss: 11225.9416\n",
      "Epoch [229], val_loss: 11095.9342\n",
      "Epoch [230], val_loss: 11113.6205\n",
      "Epoch [231], val_loss: 11313.6838\n",
      "Epoch [232], val_loss: 11106.4824\n",
      "Epoch [233], val_loss: 11205.3956\n",
      "Epoch [234], val_loss: 11048.0400\n",
      "Epoch [235], val_loss: 11214.1069\n",
      "Epoch [236], val_loss: 11056.3832\n",
      "Epoch [237], val_loss: 11085.9815\n",
      "Epoch [238], val_loss: 11081.6130\n",
      "Epoch [239], val_loss: 11753.5650\n",
      "Epoch [240], val_loss: 11011.2474\n",
      "Epoch [241], val_loss: 11027.2212\n",
      "Epoch [242], val_loss: 11010.0086\n",
      "Epoch [243], val_loss: 11103.5400\n",
      "Epoch [244], val_loss: 11038.1299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [245], val_loss: 11093.6151\n",
      "Epoch [246], val_loss: 11059.5900\n",
      "Epoch [247], val_loss: 11096.4731\n",
      "Epoch [248], val_loss: 11043.7996\n",
      "Epoch [249], val_loss: 11039.3431\n",
      "Epoch [250], val_loss: 11034.0249\n",
      "Epoch [251], val_loss: 11479.7640\n",
      "Epoch [252], val_loss: 10905.2182\n",
      "Epoch [253], val_loss: 11337.4844\n",
      "Epoch [254], val_loss: 11147.8524\n",
      "Epoch [255], val_loss: 10977.9441\n",
      "Epoch [256], val_loss: 10877.7382\n",
      "Epoch [257], val_loss: 11671.1052\n",
      "Epoch [258], val_loss: 11055.0424\n",
      "Epoch [259], val_loss: 10946.6120\n",
      "Epoch [260], val_loss: 10971.5736\n",
      "Epoch [261], val_loss: 10971.1269\n",
      "Epoch [262], val_loss: 10880.9794\n",
      "Epoch [263], val_loss: 11064.4772\n",
      "Epoch [264], val_loss: 10819.5572\n",
      "Epoch [265], val_loss: 10803.1322\n",
      "Epoch [266], val_loss: 11444.8991\n",
      "Epoch [267], val_loss: 10784.2492\n",
      "Epoch [268], val_loss: 10831.6040\n",
      "Epoch [269], val_loss: 10943.5566\n",
      "Epoch [270], val_loss: 10875.8838\n",
      "Epoch [271], val_loss: 11584.7280\n",
      "Epoch [272], val_loss: 10790.5086\n",
      "Epoch [273], val_loss: 11155.4643\n",
      "Epoch [274], val_loss: 10755.4680\n",
      "Epoch [275], val_loss: 10746.0907\n",
      "Epoch [276], val_loss: 10889.7234\n",
      "Epoch [277], val_loss: 10801.6233\n",
      "Epoch [278], val_loss: 10802.2544\n",
      "Epoch [279], val_loss: 10693.0983\n",
      "Epoch [280], val_loss: 10995.5316\n",
      "Epoch [281], val_loss: 10709.0249\n",
      "Epoch [282], val_loss: 10732.5942\n",
      "Epoch [283], val_loss: 10671.6794\n",
      "Epoch [284], val_loss: 10718.0277\n",
      "Epoch [285], val_loss: 10796.5233\n",
      "Epoch [286], val_loss: 10647.5369\n",
      "Epoch [287], val_loss: 10631.0275\n",
      "Epoch [288], val_loss: 10769.6964\n",
      "Epoch [289], val_loss: 10724.0382\n",
      "Epoch [290], val_loss: 10711.7500\n",
      "Epoch [291], val_loss: 10598.4241\n",
      "Epoch [292], val_loss: 10725.2833\n",
      "Epoch [293], val_loss: 10674.0238\n",
      "Epoch [294], val_loss: 10635.0770\n",
      "Epoch [295], val_loss: 10881.7418\n",
      "Epoch [296], val_loss: 10644.1433\n",
      "Epoch [297], val_loss: 10664.6110\n",
      "Epoch [298], val_loss: 10615.1841\n",
      "Epoch [299], val_loss: 10932.2234\n",
      "Epoch [300], val_loss: 10535.6992\n",
      "Epoch [301], val_loss: 11061.9844\n",
      "Epoch [302], val_loss: 10513.8886\n",
      "Epoch [303], val_loss: 10759.8031\n",
      "Epoch [304], val_loss: 10686.0172\n",
      "Epoch [305], val_loss: 10583.5650\n",
      "Epoch [306], val_loss: 10914.0380\n",
      "Epoch [307], val_loss: 10606.2094\n",
      "Epoch [308], val_loss: 10732.6934\n",
      "Epoch [309], val_loss: 10805.3401\n",
      "Epoch [310], val_loss: 10492.8121\n",
      "Epoch [311], val_loss: 10642.8193\n",
      "Epoch [312], val_loss: 10528.6780\n",
      "Epoch [313], val_loss: 10457.0253\n",
      "Epoch [314], val_loss: 10552.0435\n",
      "Epoch [315], val_loss: 10930.1399\n",
      "Epoch [316], val_loss: 10414.3186\n",
      "Epoch [317], val_loss: 10543.0761\n",
      "Epoch [318], val_loss: 10416.5143\n",
      "Epoch [319], val_loss: 10425.1985\n",
      "Epoch [320], val_loss: 10516.8942\n",
      "Epoch [321], val_loss: 10755.8699\n",
      "Epoch [322], val_loss: 10359.2968\n",
      "Epoch [323], val_loss: 10690.4329\n",
      "Epoch [324], val_loss: 10606.2996\n",
      "Epoch [325], val_loss: 10350.9102\n",
      "Epoch [326], val_loss: 10389.0705\n",
      "Epoch [327], val_loss: 10402.1819\n",
      "Epoch [328], val_loss: 10340.0418\n",
      "Epoch [329], val_loss: 10555.8568\n",
      "Epoch [330], val_loss: 10545.0740\n",
      "Epoch [331], val_loss: 10438.8113\n",
      "Epoch [332], val_loss: 10354.7455\n",
      "Epoch [333], val_loss: 10345.4820\n",
      "Epoch [334], val_loss: 10573.8357\n",
      "Epoch [335], val_loss: 10263.4499\n",
      "Epoch [336], val_loss: 10255.4524\n",
      "Epoch [337], val_loss: 10699.9578\n",
      "Epoch [338], val_loss: 10299.3102\n",
      "Epoch [339], val_loss: 10350.0413\n",
      "Epoch [340], val_loss: 10240.5027\n",
      "Epoch [341], val_loss: 10368.1219\n",
      "Epoch [342], val_loss: 10572.4447\n",
      "Epoch [343], val_loss: 10278.5226\n",
      "Epoch [344], val_loss: 10308.9005\n",
      "Epoch [345], val_loss: 10426.8637\n",
      "Epoch [346], val_loss: 10311.6703\n",
      "Epoch [347], val_loss: 10188.4794\n",
      "Epoch [348], val_loss: 10200.1271\n",
      "Epoch [349], val_loss: 10203.8670\n",
      "Epoch [350], val_loss: 10320.5973\n",
      "Epoch [351], val_loss: 10714.7747\n",
      "Epoch [352], val_loss: 10358.5311\n",
      "Epoch [353], val_loss: 10516.8927\n",
      "Epoch [354], val_loss: 10182.9284\n",
      "Epoch [355], val_loss: 10484.0929\n",
      "Epoch [356], val_loss: 10258.7552\n",
      "Epoch [357], val_loss: 10790.6743\n",
      "Epoch [358], val_loss: 10187.0500\n",
      "Epoch [359], val_loss: 10214.1365\n",
      "Epoch [360], val_loss: 10569.1710\n",
      "Epoch [361], val_loss: 10235.0667\n",
      "Epoch [362], val_loss: 10086.3454\n",
      "Epoch [363], val_loss: 11079.4932\n",
      "Epoch [364], val_loss: 10101.8992\n",
      "Epoch [365], val_loss: 10260.9726\n",
      "Epoch [366], val_loss: 10156.8566\n",
      "Epoch [367], val_loss: 10033.1015\n",
      "Epoch [368], val_loss: 10046.6568\n",
      "Epoch [369], val_loss: 10227.0693\n",
      "Epoch [370], val_loss: 10186.3145\n",
      "Epoch [371], val_loss: 10241.0139\n",
      "Epoch [372], val_loss: 10022.2332\n",
      "Epoch [373], val_loss: 10042.4877\n",
      "Epoch [374], val_loss: 9994.9701\n",
      "Epoch [375], val_loss: 10034.0759\n",
      "Epoch [376], val_loss: 10101.6976\n",
      "Epoch [377], val_loss: 10049.1077\n",
      "Epoch [378], val_loss: 9987.3961\n",
      "Epoch [379], val_loss: 9968.5481\n",
      "Epoch [380], val_loss: 9950.8581\n",
      "Epoch [381], val_loss: 10707.8384\n",
      "Epoch [382], val_loss: 10112.9398\n",
      "Epoch [383], val_loss: 9917.1844\n",
      "Epoch [384], val_loss: 10244.1143\n",
      "Epoch [385], val_loss: 9907.7970\n",
      "Epoch [386], val_loss: 10212.5908\n",
      "Epoch [387], val_loss: 9899.6180\n",
      "Epoch [388], val_loss: 9924.1304\n",
      "Epoch [389], val_loss: 10061.3222\n",
      "Epoch [390], val_loss: 10107.7962\n",
      "Epoch [391], val_loss: 10214.6677\n",
      "Epoch [392], val_loss: 10011.7341\n",
      "Epoch [393], val_loss: 9854.4631\n",
      "Epoch [394], val_loss: 10026.5113\n",
      "Epoch [395], val_loss: 9849.2443\n",
      "Epoch [396], val_loss: 9878.3350\n",
      "Epoch [397], val_loss: 9860.0886\n",
      "Epoch [398], val_loss: 10269.9744\n",
      "Epoch [399], val_loss: 9816.5393\n",
      "Epoch [400], val_loss: 9890.2709\n",
      "Epoch [401], val_loss: 10009.1690\n",
      "Epoch [402], val_loss: 10116.4207\n",
      "Epoch [403], val_loss: 9943.6031\n",
      "Epoch [404], val_loss: 9954.9812\n",
      "Epoch [405], val_loss: 10064.3106\n",
      "Epoch [406], val_loss: 10013.0921\n",
      "Epoch [407], val_loss: 9756.4770\n",
      "Epoch [408], val_loss: 10303.7364\n",
      "Epoch [409], val_loss: 10024.9950\n",
      "Epoch [410], val_loss: 9737.6301\n",
      "Epoch [411], val_loss: 9728.3089\n",
      "Epoch [412], val_loss: 9894.3150\n",
      "Epoch [413], val_loss: 9984.2958\n",
      "Epoch [414], val_loss: 9722.5102\n",
      "Epoch [415], val_loss: 9859.3268\n",
      "Epoch [416], val_loss: 9779.2344\n",
      "Epoch [417], val_loss: 9862.8057\n",
      "Epoch [418], val_loss: 10373.9399\n",
      "Epoch [419], val_loss: 10115.3632\n",
      "Epoch [420], val_loss: 9686.8629\n",
      "Epoch [421], val_loss: 9744.7836\n",
      "Epoch [422], val_loss: 9762.4687\n",
      "Epoch [423], val_loss: 9663.4586\n",
      "Epoch [424], val_loss: 9852.8505\n",
      "Epoch [425], val_loss: 10282.0930\n",
      "Epoch [426], val_loss: 9665.3303\n",
      "Epoch [427], val_loss: 9663.9625\n",
      "Epoch [428], val_loss: 9628.7306\n",
      "Epoch [429], val_loss: 9699.6238\n",
      "Epoch [430], val_loss: 9885.3583\n",
      "Epoch [431], val_loss: 9610.7968\n",
      "Epoch [432], val_loss: 9648.2446\n",
      "Epoch [433], val_loss: 9601.2509\n",
      "Epoch [434], val_loss: 9728.3291\n",
      "Epoch [435], val_loss: 9765.6605\n",
      "Epoch [436], val_loss: 9700.3046\n",
      "Epoch [437], val_loss: 9695.7910\n",
      "Epoch [438], val_loss: 10009.6040\n",
      "Epoch [439], val_loss: 10197.0706\n",
      "Epoch [440], val_loss: 9542.2116\n",
      "Epoch [441], val_loss: 9635.1910\n",
      "Epoch [442], val_loss: 9580.6939\n",
      "Epoch [443], val_loss: 9555.8856\n",
      "Epoch [444], val_loss: 9580.4436\n",
      "Epoch [445], val_loss: 9512.6534\n",
      "Epoch [446], val_loss: 9821.4521\n",
      "Epoch [447], val_loss: 10066.8588\n",
      "Epoch [448], val_loss: 9529.8523\n",
      "Epoch [449], val_loss: 9476.8778\n",
      "Epoch [450], val_loss: 9580.1847\n",
      "Epoch [451], val_loss: 9992.9981\n",
      "Epoch [452], val_loss: 9489.4485\n",
      "Epoch [453], val_loss: 9898.6590\n",
      "Epoch [454], val_loss: 9532.4800\n",
      "Epoch [455], val_loss: 9658.0116\n",
      "Epoch [456], val_loss: 9453.8110\n",
      "Epoch [457], val_loss: 9569.5593\n",
      "Epoch [458], val_loss: 9497.5463\n",
      "Epoch [459], val_loss: 9425.8750\n",
      "Epoch [460], val_loss: 9562.5300\n",
      "Epoch [461], val_loss: 9513.2232\n",
      "Epoch [462], val_loss: 9578.6200\n",
      "Epoch [463], val_loss: 9400.4977\n",
      "Epoch [464], val_loss: 10038.6417\n",
      "Epoch [465], val_loss: 9430.6350\n",
      "Epoch [466], val_loss: 9724.2655\n",
      "Epoch [467], val_loss: 9394.9291\n",
      "Epoch [468], val_loss: 9383.6461\n",
      "Epoch [469], val_loss: 9406.8164\n",
      "Epoch [470], val_loss: 9526.0926\n",
      "Epoch [471], val_loss: 9348.1412\n",
      "Epoch [472], val_loss: 9368.8832\n",
      "Epoch [473], val_loss: 9342.7082\n",
      "Epoch [474], val_loss: 9397.4000\n",
      "Epoch [475], val_loss: 9326.0463\n",
      "Epoch [476], val_loss: 9571.1263\n",
      "Epoch [477], val_loss: 9447.6769\n",
      "Epoch [478], val_loss: 9303.9165\n",
      "Epoch [479], val_loss: 9308.3063\n",
      "Epoch [480], val_loss: 9308.5848\n",
      "Epoch [481], val_loss: 9304.3120\n",
      "Epoch [482], val_loss: 9319.1257\n",
      "Epoch [483], val_loss: 9360.6434\n",
      "Epoch [484], val_loss: 9555.0057\n",
      "Epoch [485], val_loss: 9351.7370\n",
      "Epoch [486], val_loss: 9378.8866\n",
      "Epoch [487], val_loss: 9272.9940\n",
      "Epoch [488], val_loss: 9412.3146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [489], val_loss: 9768.4043\n",
      "Epoch [490], val_loss: 9269.9269\n",
      "Epoch [491], val_loss: 9214.1574\n",
      "Epoch [492], val_loss: 9301.8548\n",
      "Epoch [493], val_loss: 9351.4600\n",
      "Epoch [494], val_loss: 9495.0837\n",
      "Epoch [495], val_loss: 9327.8991\n",
      "Epoch [496], val_loss: 9311.6255\n",
      "Epoch [497], val_loss: 9266.8765\n",
      "Epoch [498], val_loss: 9634.1670\n",
      "Epoch [499], val_loss: 9187.9700\n",
      "Epoch [500], val_loss: 9400.5766\n",
      "Epoch [501], val_loss: 9195.5034\n",
      "Epoch [502], val_loss: 9179.6932\n",
      "Epoch [503], val_loss: 9325.1304\n",
      "Epoch [504], val_loss: 9516.2570\n",
      "Epoch [505], val_loss: 9210.2450\n",
      "Epoch [506], val_loss: 9240.2714\n",
      "Epoch [507], val_loss: 9134.7598\n",
      "Epoch [508], val_loss: 9287.3514\n",
      "Epoch [509], val_loss: 9327.6464\n",
      "Epoch [510], val_loss: 9633.5975\n",
      "Epoch [511], val_loss: 9201.1973\n",
      "Epoch [512], val_loss: 9527.2616\n",
      "Epoch [513], val_loss: 9171.6223\n",
      "Epoch [514], val_loss: 9912.6066\n",
      "Epoch [515], val_loss: 9132.6830\n",
      "Epoch [516], val_loss: 9218.3547\n",
      "Epoch [517], val_loss: 9099.5385\n",
      "Epoch [518], val_loss: 9307.0203\n",
      "Epoch [519], val_loss: 9145.1840\n",
      "Epoch [520], val_loss: 9298.1322\n",
      "Epoch [521], val_loss: 9398.5623\n",
      "Epoch [522], val_loss: 9310.1581\n",
      "Epoch [523], val_loss: 9037.3126\n",
      "Epoch [524], val_loss: 9038.2199\n",
      "Epoch [525], val_loss: 9290.0835\n",
      "Epoch [526], val_loss: 9190.6124\n",
      "Epoch [527], val_loss: 9301.0344\n",
      "Epoch [528], val_loss: 9314.1418\n",
      "Epoch [529], val_loss: 8998.5740\n",
      "Epoch [530], val_loss: 9103.0089\n",
      "Epoch [531], val_loss: 8985.2802\n",
      "Epoch [532], val_loss: 8986.6608\n",
      "Epoch [533], val_loss: 9097.2588\n",
      "Epoch [534], val_loss: 9237.7373\n",
      "Epoch [535], val_loss: 9011.3743\n",
      "Epoch [536], val_loss: 9060.8857\n",
      "Epoch [537], val_loss: 9712.0737\n",
      "Epoch [538], val_loss: 8948.2350\n",
      "Epoch [539], val_loss: 8970.5577\n",
      "Epoch [540], val_loss: 9475.9908\n",
      "Epoch [541], val_loss: 9109.8819\n",
      "Epoch [542], val_loss: 9027.6821\n",
      "Epoch [543], val_loss: 9058.0458\n",
      "Epoch [544], val_loss: 8940.4680\n",
      "Epoch [545], val_loss: 8970.6275\n",
      "Epoch [546], val_loss: 9143.4823\n",
      "Epoch [547], val_loss: 8892.8773\n",
      "Epoch [548], val_loss: 8940.1854\n",
      "Epoch [549], val_loss: 8894.4786\n",
      "Epoch [550], val_loss: 8921.3363\n",
      "Epoch [551], val_loss: 8970.4726\n",
      "Epoch [552], val_loss: 8899.7873\n",
      "Epoch [553], val_loss: 8897.0917\n",
      "Epoch [554], val_loss: 9357.1880\n",
      "Epoch [555], val_loss: 9257.6551\n",
      "Epoch [556], val_loss: 8914.4635\n",
      "Epoch [557], val_loss: 8856.2502\n",
      "Epoch [558], val_loss: 8873.8731\n",
      "Epoch [559], val_loss: 9085.9643\n",
      "Epoch [560], val_loss: 8997.6801\n",
      "Epoch [561], val_loss: 9252.1344\n",
      "Epoch [562], val_loss: 8826.2255\n",
      "Epoch [563], val_loss: 8821.5255\n",
      "Epoch [564], val_loss: 8877.0143\n",
      "Epoch [565], val_loss: 8813.6980\n",
      "Epoch [566], val_loss: 8844.8721\n",
      "Epoch [567], val_loss: 9517.5964\n",
      "Epoch [568], val_loss: 8943.1438\n",
      "Epoch [569], val_loss: 8812.1558\n",
      "Epoch [570], val_loss: 9026.8584\n",
      "Epoch [571], val_loss: 8861.3946\n",
      "Epoch [572], val_loss: 8785.3721\n",
      "Epoch [573], val_loss: 9043.2939\n",
      "Epoch [574], val_loss: 9135.3506\n",
      "Epoch [575], val_loss: 8856.9895\n",
      "Epoch [576], val_loss: 8753.3279\n",
      "Epoch [577], val_loss: 9108.4262\n",
      "Epoch [578], val_loss: 8738.2507\n",
      "Epoch [579], val_loss: 8758.6069\n",
      "Epoch [580], val_loss: 8721.9385\n",
      "Epoch [581], val_loss: 8797.5810\n",
      "Epoch [582], val_loss: 8717.1790\n",
      "Epoch [583], val_loss: 8923.6092\n",
      "Epoch [584], val_loss: 8739.4105\n",
      "Epoch [585], val_loss: 8782.5828\n",
      "Epoch [586], val_loss: 8705.0445\n",
      "Epoch [587], val_loss: 8770.5498\n",
      "Epoch [588], val_loss: 8945.3534\n",
      "Epoch [589], val_loss: 8686.7719\n",
      "Epoch [590], val_loss: 8682.8955\n",
      "Epoch [591], val_loss: 8681.8951\n",
      "Epoch [592], val_loss: 8750.4427\n",
      "Epoch [593], val_loss: 8797.8123\n",
      "Epoch [594], val_loss: 8873.2595\n",
      "Epoch [595], val_loss: 8759.3627\n",
      "Epoch [596], val_loss: 8786.1122\n",
      "Epoch [597], val_loss: 8645.0448\n",
      "Epoch [598], val_loss: 8999.2256\n",
      "Epoch [599], val_loss: 8715.1278\n",
      "Epoch [600], val_loss: 8746.3226\n",
      "Epoch [601], val_loss: 8670.9596\n",
      "Epoch [602], val_loss: 8611.0955\n",
      "Epoch [603], val_loss: 8643.1750\n",
      "Epoch [604], val_loss: 8698.0148\n",
      "Epoch [605], val_loss: 8812.7164\n",
      "Epoch [606], val_loss: 8591.2435\n",
      "Epoch [607], val_loss: 8696.8711\n",
      "Epoch [608], val_loss: 8650.7657\n",
      "Epoch [609], val_loss: 8604.3285\n",
      "Epoch [610], val_loss: 8760.5875\n",
      "Epoch [611], val_loss: 8899.9222\n",
      "Epoch [612], val_loss: 8932.2762\n",
      "Epoch [613], val_loss: 8568.6923\n",
      "Epoch [614], val_loss: 8640.2424\n",
      "Epoch [615], val_loss: 8567.5498\n",
      "Epoch [616], val_loss: 8552.4120\n",
      "Epoch [617], val_loss: 8583.7731\n",
      "Epoch [618], val_loss: 8584.9968\n",
      "Epoch [619], val_loss: 8660.8126\n",
      "Epoch [620], val_loss: 8650.0684\n",
      "Epoch [621], val_loss: 8677.2043\n",
      "Epoch [622], val_loss: 8611.1081\n",
      "Epoch [623], val_loss: 8507.9018\n",
      "Epoch [624], val_loss: 8648.9241\n",
      "Epoch [625], val_loss: 8517.7180\n",
      "Epoch [626], val_loss: 8510.4301\n",
      "Epoch [627], val_loss: 8513.0657\n",
      "Epoch [628], val_loss: 8485.4521\n",
      "Epoch [629], val_loss: 8527.5651\n",
      "Epoch [630], val_loss: 8500.6673\n",
      "Epoch [631], val_loss: 8535.4046\n",
      "Epoch [632], val_loss: 9493.6763\n",
      "Epoch [633], val_loss: 9254.5652\n",
      "Epoch [634], val_loss: 8559.7333\n",
      "Epoch [635], val_loss: 8452.3128\n",
      "Epoch [636], val_loss: 8451.2677\n",
      "Epoch [637], val_loss: 8449.3026\n",
      "Epoch [638], val_loss: 8443.6376\n",
      "Epoch [639], val_loss: 8498.5359\n",
      "Epoch [640], val_loss: 8726.4856\n",
      "Epoch [641], val_loss: 8489.9846\n",
      "Epoch [642], val_loss: 8656.4399\n",
      "Epoch [643], val_loss: 8581.0476\n",
      "Epoch [644], val_loss: 8407.0932\n",
      "Epoch [645], val_loss: 9341.2945\n",
      "Epoch [646], val_loss: 8455.4290\n",
      "Epoch [647], val_loss: 8399.5611\n",
      "Epoch [648], val_loss: 8403.1178\n",
      "Epoch [649], val_loss: 8881.1203\n"
     ]
    }
   ],
   "source": [
    "model.training_(650, 1, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a18539e7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 8866.6191\n",
      "Epoch [1], val_loss: 8850.8699\n",
      "Epoch [2], val_loss: 8838.0280\n",
      "Epoch [3], val_loss: 8825.5098\n",
      "Epoch [4], val_loss: 8813.6070\n",
      "Epoch [5], val_loss: 8800.9749\n",
      "Epoch [6], val_loss: 8789.8718\n",
      "Epoch [7], val_loss: 8778.6382\n",
      "Epoch [8], val_loss: 8766.6960\n",
      "Epoch [9], val_loss: 8756.6818\n",
      "Epoch [10], val_loss: 8746.3934\n",
      "Epoch [11], val_loss: 8737.3832\n",
      "Epoch [12], val_loss: 8729.6268\n",
      "Epoch [13], val_loss: 8720.4361\n",
      "Epoch [14], val_loss: 8712.7721\n",
      "Epoch [15], val_loss: 8704.9606\n",
      "Epoch [16], val_loss: 8698.3178\n",
      "Epoch [17], val_loss: 8691.1761\n",
      "Epoch [18], val_loss: 8685.2966\n",
      "Epoch [19], val_loss: 8678.7794\n",
      "Epoch [20], val_loss: 8672.5104\n",
      "Epoch [21], val_loss: 8665.3377\n",
      "Epoch [22], val_loss: 8659.7957\n",
      "Epoch [23], val_loss: 8654.5841\n",
      "Epoch [24], val_loss: 8646.8958\n",
      "Epoch [25], val_loss: 8642.0398\n",
      "Epoch [26], val_loss: 8637.3353\n",
      "Epoch [27], val_loss: 8631.9758\n",
      "Epoch [28], val_loss: 8627.9015\n",
      "Epoch [29], val_loss: 8623.2171\n",
      "Epoch [30], val_loss: 8619.2292\n",
      "Epoch [31], val_loss: 8615.4618\n",
      "Epoch [32], val_loss: 8611.7670\n",
      "Epoch [33], val_loss: 8608.0049\n",
      "Epoch [34], val_loss: 8604.3184\n",
      "Epoch [35], val_loss: 8601.6892\n",
      "Epoch [36], val_loss: 8597.5893\n",
      "Epoch [37], val_loss: 8593.3569\n",
      "Epoch [38], val_loss: 8590.6141\n",
      "Epoch [39], val_loss: 8586.6182\n",
      "Epoch [40], val_loss: 8584.8534\n",
      "Epoch [41], val_loss: 8582.1673\n",
      "Epoch [42], val_loss: 8578.7340\n",
      "Epoch [43], val_loss: 8576.5446\n",
      "Epoch [44], val_loss: 8574.9427\n",
      "Epoch [45], val_loss: 8572.8748\n",
      "Epoch [46], val_loss: 8570.1572\n",
      "Epoch [47], val_loss: 8568.1474\n",
      "Epoch [48], val_loss: 8565.8947\n",
      "Epoch [49], val_loss: 8564.3907\n",
      "Epoch [50], val_loss: 8562.9321\n",
      "Epoch [51], val_loss: 8561.4567\n",
      "Epoch [52], val_loss: 8559.6925\n",
      "Epoch [53], val_loss: 8557.1467\n",
      "Epoch [54], val_loss: 8555.0905\n",
      "Epoch [55], val_loss: 8552.6715\n",
      "Epoch [56], val_loss: 8550.4141\n",
      "Epoch [57], val_loss: 8549.3466\n",
      "Epoch [58], val_loss: 8547.5449\n",
      "Epoch [59], val_loss: 8545.4246\n",
      "Epoch [60], val_loss: 8543.3382\n",
      "Epoch [61], val_loss: 8541.6161\n",
      "Epoch [62], val_loss: 8539.9730\n",
      "Epoch [63], val_loss: 8539.0259\n",
      "Epoch [64], val_loss: 8537.6299\n",
      "Epoch [65], val_loss: 8536.6705\n",
      "Epoch [66], val_loss: 8535.2196\n",
      "Epoch [67], val_loss: 8534.4635\n",
      "Epoch [68], val_loss: 8533.4816\n",
      "Epoch [69], val_loss: 8532.0011\n",
      "Epoch [70], val_loss: 8530.7724\n",
      "Epoch [71], val_loss: 8529.7526\n",
      "Epoch [72], val_loss: 8528.3098\n",
      "Epoch [73], val_loss: 8527.1829\n",
      "Epoch [74], val_loss: 8526.2053\n",
      "Epoch [75], val_loss: 8525.3641\n",
      "Epoch [76], val_loss: 8523.5291\n",
      "Epoch [77], val_loss: 8522.6475\n",
      "Epoch [78], val_loss: 8521.6565\n",
      "Epoch [79], val_loss: 8520.5193\n",
      "Epoch [80], val_loss: 8519.7137\n",
      "Epoch [81], val_loss: 8519.0464\n",
      "Epoch [82], val_loss: 8518.8555\n",
      "Epoch [83], val_loss: 8517.9150\n",
      "Epoch [84], val_loss: 8517.1107\n",
      "Epoch [85], val_loss: 8516.1409\n",
      "Epoch [86], val_loss: 8515.5121\n",
      "Epoch [87], val_loss: 8514.7191\n",
      "Epoch [88], val_loss: 8514.3549\n",
      "Epoch [89], val_loss: 8513.4446\n",
      "Epoch [90], val_loss: 8513.0480\n",
      "Epoch [91], val_loss: 8512.9176\n",
      "Epoch [92], val_loss: 8512.0512\n",
      "Epoch [93], val_loss: 8511.1701\n",
      "Epoch [94], val_loss: 8510.3141\n",
      "Epoch [95], val_loss: 8510.0307\n",
      "Epoch [96], val_loss: 8509.7618\n",
      "Epoch [97], val_loss: 8508.9610\n",
      "Epoch [98], val_loss: 8507.9744\n",
      "Epoch [99], val_loss: 8507.5166\n",
      "Epoch [100], val_loss: 8507.3526\n",
      "Epoch [101], val_loss: 8508.0352\n",
      "Epoch [102], val_loss: 8507.4999\n",
      "Epoch [103], val_loss: 8506.9248\n",
      "Epoch [104], val_loss: 8505.5889\n",
      "Epoch [105], val_loss: 8505.5462\n",
      "Epoch [106], val_loss: 8505.7952\n",
      "Epoch [107], val_loss: 8505.6118\n",
      "Epoch [108], val_loss: 8505.4272\n",
      "Epoch [109], val_loss: 8505.3963\n",
      "Epoch [110], val_loss: 8505.1484\n",
      "Epoch [111], val_loss: 8504.5488\n",
      "Epoch [112], val_loss: 8504.1641\n",
      "Epoch [113], val_loss: 8503.8950\n",
      "Epoch [114], val_loss: 8504.0858\n",
      "Epoch [115], val_loss: 8503.8876\n",
      "Epoch [116], val_loss: 8504.5412\n",
      "Epoch [117], val_loss: 8504.0289\n",
      "Epoch [118], val_loss: 8504.1385\n",
      "Epoch [119], val_loss: 8503.7385\n",
      "Epoch [120], val_loss: 8503.1309\n",
      "Epoch [121], val_loss: 8502.3724\n",
      "Epoch [122], val_loss: 8502.1286\n",
      "Epoch [123], val_loss: 8501.4618\n",
      "Epoch [124], val_loss: 8501.2633\n",
      "Epoch [125], val_loss: 8500.3409\n",
      "Epoch [126], val_loss: 8500.3039\n",
      "Epoch [127], val_loss: 8500.5209\n",
      "Epoch [128], val_loss: 8500.3555\n",
      "Epoch [129], val_loss: 8500.4071\n",
      "Epoch [130], val_loss: 8499.9925\n",
      "Epoch [131], val_loss: 8499.7119\n",
      "Epoch [132], val_loss: 8499.9159\n",
      "Epoch [133], val_loss: 8499.5839\n",
      "Epoch [134], val_loss: 8499.2450\n",
      "Epoch [135], val_loss: 8499.3728\n",
      "Epoch [136], val_loss: 8499.0800\n",
      "Epoch [137], val_loss: 8499.1236\n",
      "Epoch [138], val_loss: 8498.5383\n",
      "Epoch [139], val_loss: 8497.8281\n",
      "Epoch [140], val_loss: 8498.1495\n",
      "Epoch [141], val_loss: 8498.3124\n",
      "Epoch [142], val_loss: 8497.7280\n",
      "Epoch [143], val_loss: 8498.5131\n",
      "Epoch [144], val_loss: 8498.6811\n",
      "Epoch [145], val_loss: 8498.7253\n",
      "Epoch [146], val_loss: 8499.0491\n",
      "Epoch [147], val_loss: 8498.9901\n",
      "Epoch [148], val_loss: 8498.5933\n",
      "Epoch [149], val_loss: 8498.2058\n",
      "Epoch [150], val_loss: 8497.8539\n",
      "Epoch [151], val_loss: 8497.4784\n",
      "Epoch [152], val_loss: 8497.7668\n",
      "Epoch [153], val_loss: 8497.4913\n",
      "Epoch [154], val_loss: 8497.7804\n",
      "Epoch [155], val_loss: 8497.0949\n",
      "Epoch [156], val_loss: 8497.2340\n",
      "Epoch [157], val_loss: 8496.5916\n",
      "Epoch [158], val_loss: 8496.7121\n",
      "Epoch [159], val_loss: 8496.3139\n",
      "Epoch [160], val_loss: 8496.4913\n",
      "Epoch [161], val_loss: 8497.6365\n",
      "Epoch [162], val_loss: 8497.2190\n",
      "Epoch [163], val_loss: 8497.4071\n",
      "Epoch [164], val_loss: 8497.2746\n",
      "Epoch [165], val_loss: 8496.8561\n",
      "Epoch [166], val_loss: 8496.6455\n",
      "Epoch [167], val_loss: 8496.6932\n",
      "Epoch [168], val_loss: 8495.6843\n",
      "Epoch [169], val_loss: 8495.8056\n",
      "Epoch [170], val_loss: 8495.8551\n",
      "Epoch [171], val_loss: 8496.1138\n",
      "Epoch [172], val_loss: 8495.4445\n",
      "Epoch [173], val_loss: 8494.8705\n",
      "Epoch [174], val_loss: 8495.2182\n",
      "Epoch [175], val_loss: 8495.8371\n",
      "Epoch [176], val_loss: 8495.4860\n",
      "Epoch [177], val_loss: 8495.6189\n",
      "Epoch [178], val_loss: 8495.8416\n",
      "Epoch [179], val_loss: 8495.8737\n",
      "Epoch [180], val_loss: 8495.2144\n",
      "Epoch [181], val_loss: 8495.4646\n",
      "Epoch [182], val_loss: 8495.9360\n",
      "Epoch [183], val_loss: 8495.3349\n",
      "Epoch [184], val_loss: 8495.4458\n",
      "Epoch [185], val_loss: 8496.1130\n",
      "Epoch [186], val_loss: 8496.1364\n",
      "Epoch [187], val_loss: 8495.7297\n",
      "Epoch [188], val_loss: 8495.3525\n",
      "Epoch [189], val_loss: 8494.9498\n",
      "Epoch [190], val_loss: 8495.3272\n",
      "Epoch [191], val_loss: 8495.2819\n",
      "Epoch [192], val_loss: 8495.8722\n",
      "Epoch [193], val_loss: 8495.6762\n",
      "Epoch [194], val_loss: 8495.1378\n",
      "Epoch [195], val_loss: 8494.2608\n",
      "Epoch [196], val_loss: 8494.1067\n",
      "Epoch [197], val_loss: 8494.7399\n",
      "Epoch [198], val_loss: 8494.7267\n",
      "Epoch [199], val_loss: 8494.8151\n",
      "Epoch [200], val_loss: 8494.4635\n",
      "Epoch [201], val_loss: 8494.5234\n",
      "Epoch [202], val_loss: 8493.7732\n",
      "Epoch [203], val_loss: 8494.5393\n",
      "Epoch [204], val_loss: 8493.8131\n",
      "Epoch [205], val_loss: 8493.5050\n",
      "Epoch [206], val_loss: 8493.3111\n",
      "Epoch [207], val_loss: 8492.8156\n",
      "Epoch [208], val_loss: 8493.4637\n",
      "Epoch [209], val_loss: 8493.7148\n",
      "Epoch [210], val_loss: 8494.1314\n",
      "Epoch [211], val_loss: 8493.9515\n",
      "Epoch [212], val_loss: 8494.1161\n",
      "Epoch [213], val_loss: 8493.6387\n",
      "Epoch [214], val_loss: 8494.0567\n",
      "Epoch [215], val_loss: 8493.9220\n",
      "Epoch [216], val_loss: 8494.1495\n",
      "Epoch [217], val_loss: 8493.8223\n",
      "Epoch [218], val_loss: 8494.1101\n",
      "Epoch [219], val_loss: 8494.3902\n",
      "Epoch [220], val_loss: 8494.6905\n",
      "Epoch [221], val_loss: 8493.8540\n",
      "Epoch [222], val_loss: 8493.6054\n",
      "Epoch [223], val_loss: 8493.3966\n",
      "Epoch [224], val_loss: 8493.5442\n",
      "Epoch [225], val_loss: 8494.0572\n",
      "Epoch [226], val_loss: 8493.8788\n",
      "Epoch [227], val_loss: 8494.0213\n",
      "Epoch [228], val_loss: 8494.8533\n",
      "Epoch [229], val_loss: 8495.3849\n",
      "Epoch [230], val_loss: 8495.7990\n",
      "Epoch [231], val_loss: 8495.6218\n",
      "Epoch [232], val_loss: 8495.6038\n",
      "Epoch [233], val_loss: 8495.4326\n",
      "Epoch [234], val_loss: 8494.6673\n",
      "Epoch [235], val_loss: 8494.7699\n",
      "Epoch [236], val_loss: 8495.1676\n",
      "Epoch [237], val_loss: 8495.3525\n",
      "Epoch [238], val_loss: 8494.7053\n",
      "Epoch [239], val_loss: 8494.9046\n",
      "Epoch [240], val_loss: 8495.3907\n",
      "Epoch [241], val_loss: 8495.2648\n",
      "Epoch [242], val_loss: 8495.4125\n",
      "Epoch [243], val_loss: 8495.8138\n",
      "Epoch [244], val_loss: 8496.2005\n",
      "Epoch [245], val_loss: 8495.5350\n",
      "Epoch [246], val_loss: 8496.0174\n",
      "Epoch [247], val_loss: 8495.6693\n",
      "Epoch [248], val_loss: 8495.1674\n",
      "Epoch [249], val_loss: 8495.0022\n"
     ]
    }
   ],
   "source": [
    "model.training_(250, 0.001, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b5d0b87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 6635.9331\n",
      "Epoch [1], val_loss: 6575.2905\n",
      "Epoch [2], val_loss: 6629.4360\n",
      "Epoch [3], val_loss: 6657.7908\n",
      "Epoch [4], val_loss: 6643.1545\n",
      "Epoch [5], val_loss: 6626.3908\n",
      "Epoch [6], val_loss: 6643.9714\n",
      "Epoch [7], val_loss: 6667.7315\n",
      "Epoch [8], val_loss: 6632.1546\n",
      "Epoch [9], val_loss: 6637.7317\n",
      "Epoch [10], val_loss: 6686.5109\n",
      "Epoch [11], val_loss: 6663.1394\n",
      "Epoch [12], val_loss: 6678.6569\n",
      "Epoch [13], val_loss: 6644.7219\n",
      "Epoch [14], val_loss: 6666.5429\n",
      "Epoch [15], val_loss: 6627.2403\n",
      "Epoch [16], val_loss: 6628.3897\n",
      "Epoch [17], val_loss: 6662.4133\n",
      "Epoch [18], val_loss: 6645.8710\n",
      "Epoch [19], val_loss: 6598.8474\n",
      "Epoch [20], val_loss: 6589.3222\n",
      "Epoch [21], val_loss: 6586.0860\n",
      "Epoch [22], val_loss: 6601.1159\n",
      "Epoch [23], val_loss: 6570.7741\n",
      "Epoch [24], val_loss: 6641.9251\n",
      "Epoch [25], val_loss: 6649.5445\n",
      "Epoch [26], val_loss: 6603.0415\n",
      "Epoch [27], val_loss: 6603.8040\n",
      "Epoch [28], val_loss: 6636.4440\n",
      "Epoch [29], val_loss: 6603.0323\n",
      "Epoch [30], val_loss: 6656.0093\n",
      "Epoch [31], val_loss: 6617.3102\n",
      "Epoch [32], val_loss: 6614.8177\n",
      "Epoch [33], val_loss: 6599.3527\n",
      "Epoch [34], val_loss: 6620.0799\n",
      "Epoch [35], val_loss: 6615.1671\n",
      "Epoch [36], val_loss: 6662.2552\n",
      "Epoch [37], val_loss: 6602.3592\n",
      "Epoch [38], val_loss: 6585.8350\n",
      "Epoch [39], val_loss: 6657.8451\n",
      "Epoch [40], val_loss: 6618.3112\n",
      "Epoch [41], val_loss: 6635.2634\n",
      "Epoch [42], val_loss: 6634.9376\n",
      "Epoch [43], val_loss: 6665.7684\n",
      "Epoch [44], val_loss: 6617.4064\n",
      "Epoch [45], val_loss: 6645.5702\n",
      "Epoch [46], val_loss: 6649.6290\n",
      "Epoch [47], val_loss: 6631.7687\n",
      "Epoch [48], val_loss: 6619.3270\n",
      "Epoch [49], val_loss: 6661.8956\n",
      "Epoch [50], val_loss: 6590.9045\n",
      "Epoch [51], val_loss: 6666.3123\n",
      "Epoch [52], val_loss: 6627.7201\n",
      "Epoch [53], val_loss: 6590.2668\n",
      "Epoch [54], val_loss: 6620.3726\n",
      "Epoch [55], val_loss: 6619.4204\n",
      "Epoch [56], val_loss: 6655.9707\n",
      "Epoch [57], val_loss: 6656.8436\n",
      "Epoch [58], val_loss: 6626.2873\n",
      "Epoch [59], val_loss: 6637.9190\n",
      "Epoch [60], val_loss: 6621.3042\n",
      "Epoch [61], val_loss: 6619.7693\n",
      "Epoch [62], val_loss: 6656.6992\n",
      "Epoch [63], val_loss: 6629.5066\n",
      "Epoch [64], val_loss: 6573.8914\n",
      "Epoch [65], val_loss: 6583.4601\n",
      "Epoch [66], val_loss: 6625.9398\n",
      "Epoch [67], val_loss: 6642.0585\n",
      "Epoch [68], val_loss: 6654.2855\n",
      "Epoch [69], val_loss: 6626.8930\n",
      "Epoch [70], val_loss: 6665.6328\n",
      "Epoch [71], val_loss: 6631.8099\n",
      "Epoch [72], val_loss: 6690.5367\n",
      "Epoch [73], val_loss: 6634.0857\n",
      "Epoch [74], val_loss: 6612.1561\n",
      "Epoch [75], val_loss: 6578.4816\n",
      "Epoch [76], val_loss: 6585.8039\n",
      "Epoch [77], val_loss: 6641.9044\n",
      "Epoch [78], val_loss: 6639.2970\n",
      "Epoch [79], val_loss: 6626.2558\n",
      "Epoch [80], val_loss: 6595.8805\n",
      "Epoch [81], val_loss: 6629.5752\n",
      "Epoch [82], val_loss: 6601.7568\n",
      "Epoch [83], val_loss: 6619.2527\n",
      "Epoch [84], val_loss: 6593.1942\n",
      "Epoch [85], val_loss: 6609.5545\n",
      "Epoch [86], val_loss: 6589.1256\n",
      "Epoch [87], val_loss: 6601.9778\n",
      "Epoch [88], val_loss: 6662.0966\n",
      "Epoch [89], val_loss: 6618.4405\n",
      "Epoch [90], val_loss: 6641.5181\n",
      "Epoch [91], val_loss: 6612.8984\n",
      "Epoch [92], val_loss: 6640.8318\n",
      "Epoch [93], val_loss: 6582.9098\n",
      "Epoch [94], val_loss: 6659.7634\n",
      "Epoch [95], val_loss: 6619.5330\n",
      "Epoch [96], val_loss: 6620.4127\n",
      "Epoch [97], val_loss: 6637.8435\n",
      "Epoch [98], val_loss: 6623.5472\n",
      "Epoch [99], val_loss: 6592.7838\n",
      "Epoch [100], val_loss: 6685.5365\n",
      "Epoch [101], val_loss: 6601.0216\n",
      "Epoch [102], val_loss: 6641.9120\n",
      "Epoch [103], val_loss: 6581.1177\n",
      "Epoch [104], val_loss: 6609.4644\n",
      "Epoch [105], val_loss: 6587.8479\n",
      "Epoch [106], val_loss: 6616.3274\n",
      "Epoch [107], val_loss: 6620.7616\n",
      "Epoch [108], val_loss: 6582.4761\n",
      "Epoch [109], val_loss: 6619.8930\n",
      "Epoch [110], val_loss: 6607.6865\n",
      "Epoch [111], val_loss: 6645.4176\n",
      "Epoch [112], val_loss: 6646.2553\n",
      "Epoch [113], val_loss: 6660.6423\n",
      "Epoch [114], val_loss: 6590.0441\n",
      "Epoch [115], val_loss: 6679.4696\n",
      "Epoch [116], val_loss: 6617.7585\n",
      "Epoch [117], val_loss: 6628.5570\n",
      "Epoch [118], val_loss: 6617.2421\n",
      "Epoch [119], val_loss: 6610.5130\n",
      "Epoch [120], val_loss: 6610.8364\n",
      "Epoch [121], val_loss: 6625.0438\n",
      "Epoch [122], val_loss: 6606.4321\n",
      "Epoch [123], val_loss: 6616.3288\n",
      "Epoch [124], val_loss: 6668.6380\n",
      "Epoch [125], val_loss: 6624.2393\n",
      "Epoch [126], val_loss: 6603.0043\n",
      "Epoch [127], val_loss: 6601.5959\n",
      "Epoch [128], val_loss: 6605.8706\n",
      "Epoch [129], val_loss: 6639.0313\n",
      "Epoch [130], val_loss: 6621.1552\n",
      "Epoch [131], val_loss: 6592.5314\n",
      "Epoch [132], val_loss: 6609.5371\n",
      "Epoch [133], val_loss: 6614.6555\n",
      "Epoch [134], val_loss: 6592.2552\n",
      "Epoch [135], val_loss: 6632.0706\n",
      "Epoch [136], val_loss: 6615.7326\n",
      "Epoch [137], val_loss: 6632.6017\n",
      "Epoch [138], val_loss: 6619.3947\n",
      "Epoch [139], val_loss: 6641.5900\n",
      "Epoch [140], val_loss: 6609.4435\n",
      "Epoch [141], val_loss: 6595.4967\n",
      "Epoch [142], val_loss: 6602.6574\n",
      "Epoch [143], val_loss: 6608.1931\n",
      "Epoch [144], val_loss: 6643.7257\n",
      "Epoch [145], val_loss: 6603.5362\n",
      "Epoch [146], val_loss: 6570.3381\n",
      "Epoch [147], val_loss: 6599.3388\n",
      "Epoch [148], val_loss: 6628.6926\n",
      "Epoch [149], val_loss: 6603.5988\n",
      "Epoch [150], val_loss: 6566.3610\n",
      "Epoch [151], val_loss: 6614.9959\n",
      "Epoch [152], val_loss: 6582.2522\n",
      "Epoch [153], val_loss: 6607.1690\n",
      "Epoch [154], val_loss: 6615.0952\n",
      "Epoch [155], val_loss: 6602.4702\n",
      "Epoch [156], val_loss: 6568.5408\n",
      "Epoch [157], val_loss: 6573.9906\n",
      "Epoch [158], val_loss: 6612.1347\n",
      "Epoch [159], val_loss: 6595.4524\n",
      "Epoch [160], val_loss: 6594.9689\n",
      "Epoch [161], val_loss: 6577.0542\n",
      "Epoch [162], val_loss: 6580.6021\n",
      "Epoch [163], val_loss: 6679.4760\n",
      "Epoch [164], val_loss: 6600.2243\n",
      "Epoch [165], val_loss: 6605.0958\n",
      "Epoch [166], val_loss: 6612.0812\n",
      "Epoch [167], val_loss: 6641.9021\n",
      "Epoch [168], val_loss: 6657.5028\n",
      "Epoch [169], val_loss: 6596.7733\n",
      "Epoch [170], val_loss: 6598.6427\n",
      "Epoch [171], val_loss: 6596.2960\n",
      "Epoch [172], val_loss: 6601.7418\n",
      "Epoch [173], val_loss: 6607.5547\n",
      "Epoch [174], val_loss: 6576.8444\n",
      "Epoch [175], val_loss: 6652.7368\n",
      "Epoch [176], val_loss: 6631.8919\n",
      "Epoch [177], val_loss: 6605.7093\n",
      "Epoch [178], val_loss: 6669.7436\n",
      "Epoch [179], val_loss: 6607.5855\n",
      "Epoch [180], val_loss: 6606.0335\n",
      "Epoch [181], val_loss: 6629.3363\n",
      "Epoch [182], val_loss: 6598.4457\n",
      "Epoch [183], val_loss: 6686.2687\n",
      "Epoch [184], val_loss: 6615.9147\n",
      "Epoch [185], val_loss: 6642.6120\n",
      "Epoch [186], val_loss: 6574.7231\n",
      "Epoch [187], val_loss: 6655.4055\n",
      "Epoch [188], val_loss: 6612.4782\n",
      "Epoch [189], val_loss: 6574.0306\n",
      "Epoch [190], val_loss: 6588.1845\n",
      "Epoch [191], val_loss: 6648.4802\n",
      "Epoch [192], val_loss: 6628.7428\n",
      "Epoch [193], val_loss: 6637.2296\n",
      "Epoch [194], val_loss: 6599.5807\n",
      "Epoch [195], val_loss: 6612.4695\n",
      "Epoch [196], val_loss: 6569.1921\n",
      "Epoch [197], val_loss: 6596.0600\n",
      "Epoch [198], val_loss: 6603.1682\n",
      "Epoch [199], val_loss: 6575.5608\n",
      "Epoch [200], val_loss: 6592.9320\n",
      "Epoch [201], val_loss: 6638.1058\n",
      "Epoch [202], val_loss: 6606.1752\n",
      "Epoch [203], val_loss: 6623.3332\n",
      "Epoch [204], val_loss: 6586.5888\n",
      "Epoch [205], val_loss: 6568.6923\n",
      "Epoch [206], val_loss: 6610.3274\n",
      "Epoch [207], val_loss: 6603.7549\n",
      "Epoch [208], val_loss: 6584.9132\n",
      "Epoch [209], val_loss: 6602.1836\n",
      "Epoch [210], val_loss: 6619.5808\n",
      "Epoch [211], val_loss: 6574.6694\n",
      "Epoch [212], val_loss: 6620.0187\n",
      "Epoch [213], val_loss: 6611.7750\n",
      "Epoch [214], val_loss: 6598.8108\n",
      "Epoch [215], val_loss: 6576.0365\n",
      "Epoch [216], val_loss: 6622.2143\n",
      "Epoch [217], val_loss: 6601.9635\n",
      "Epoch [218], val_loss: 6592.9992\n",
      "Epoch [219], val_loss: 6575.9192\n",
      "Epoch [220], val_loss: 6632.2268\n",
      "Epoch [221], val_loss: 6683.6442\n",
      "Epoch [222], val_loss: 6571.7401\n",
      "Epoch [223], val_loss: 6630.7637\n",
      "Epoch [224], val_loss: 6619.0080\n",
      "Epoch [225], val_loss: 6625.7030\n",
      "Epoch [226], val_loss: 6589.3862\n",
      "Epoch [227], val_loss: 6597.5837\n",
      "Epoch [228], val_loss: 6630.2027\n",
      "Epoch [229], val_loss: 6567.2941\n",
      "Epoch [230], val_loss: 6606.6890\n",
      "Epoch [231], val_loss: 6599.0059\n",
      "Epoch [232], val_loss: 6614.0076\n",
      "Epoch [233], val_loss: 6644.8646\n",
      "Epoch [234], val_loss: 6609.0513\n",
      "Epoch [235], val_loss: 6641.3860\n",
      "Epoch [236], val_loss: 6579.5545\n",
      "Epoch [237], val_loss: 6673.3893\n",
      "Epoch [238], val_loss: 6608.3013\n",
      "Epoch [239], val_loss: 6612.0360\n",
      "Epoch [240], val_loss: 6588.8945\n",
      "Epoch [241], val_loss: 6623.2679\n",
      "Epoch [242], val_loss: 6600.6013\n",
      "Epoch [243], val_loss: 6612.6777\n",
      "Epoch [244], val_loss: 6605.2436\n",
      "Epoch [245], val_loss: 6647.0594\n",
      "Epoch [246], val_loss: 6630.4655\n",
      "Epoch [247], val_loss: 6659.5225\n",
      "Epoch [248], val_loss: 6600.9531\n",
      "Epoch [249], val_loss: 6601.0250\n"
     ]
    }
   ],
   "source": [
    "model.training_(250, 0.1, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17f2ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(inputs, target, model):\n",
    "    print(inputs)\n",
    "    print(type(inputs))\n",
    "    pred = model.prediction(inputs)\n",
    "    return [pred, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59b700a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([31581.6337], grad_fn=<AddBackward0>), tensor([42111.6647])]\n",
      "[tensor([14989.0734], grad_fn=<AddBackward0>), tensor([14418.2804])]\n",
      "[tensor([6091.1081], grad_fn=<AddBackward0>), tensor([5116.5004])]\n",
      "[tensor([10416.0277], grad_fn=<AddBackward0>), tensor([8334.5896])]\n",
      "[tensor([10589.3001], grad_fn=<AddBackward0>), tensor([8988.1588])]\n",
      "[tensor([13422.6748], grad_fn=<AddBackward0>), tensor([11566.3005])]\n",
      "[tensor([7735.0147], grad_fn=<AddBackward0>), tensor([20420.6047])]\n",
      "[tensor([11816.0349], grad_fn=<AddBackward0>), tensor([9144.5650])]\n",
      "[tensor([28082.2301], grad_fn=<AddBackward0>), tensor([39611.7577])]\n",
      "[tensor([13127.1798], grad_fn=<AddBackward0>), tensor([10602.3850])]\n",
      "[tensor([23838.3633], grad_fn=<AddBackward0>), tensor([14283.4594])]\n",
      "[tensor([11842.7256], grad_fn=<AddBackward0>), tensor([22192.4371])]\n",
      "[tensor([6930.3480], grad_fn=<AddBackward0>), tensor([4357.0436])]\n",
      "[tensor([27543.9516], grad_fn=<AddBackward0>), tensor([18765.8754])]\n",
      "[tensor([28994.9048], grad_fn=<AddBackward0>), tensor([58571.0745])]\n",
      "[tensor([5958.8833], grad_fn=<AddBackward0>), tensor([4877.9811])]\n",
      "[tensor([11499.2711], grad_fn=<AddBackward0>), tensor([11082.5772])]\n",
      "[tensor([33564.9845], grad_fn=<AddBackward0>), tensor([43813.8661])]\n",
      "[tensor([12231.6983], grad_fn=<AddBackward0>), tensor([11353.2276])]\n",
      "[tensor([14551.5611], grad_fn=<AddBackward0>), tensor([27941.2876])]\n",
      "[tensor([30386.4126], grad_fn=<AddBackward0>), tensor([40182.2460])]\n",
      "[tensor([5189.3312], grad_fn=<AddBackward0>), tensor([2219.4451])]\n",
      "[tensor([2804.1819], grad_fn=<AddBackward0>), tensor([1607.5101])]\n",
      "[tensor([26907.0339], grad_fn=<AddBackward0>), tensor([36021.0112])]\n",
      "[tensor([13596.6109], grad_fn=<AddBackward0>), tensor([12644.5890])]\n",
      "[tensor([12500.2178], grad_fn=<AddBackward0>), tensor([30259.9956])]\n",
      "[tensor([29688.6645], grad_fn=<AddBackward0>), tensor([37829.7242])]\n",
      "[tensor([4786.2864], grad_fn=<AddBackward0>), tensor([13126.6774])]\n",
      "[tensor([6529.1478], grad_fn=<AddBackward0>), tensor([5312.1699])]\n",
      "[tensor([8184.9829], grad_fn=<AddBackward0>), tensor([6184.2994])]\n",
      "[tensor([8050.8015], grad_fn=<AddBackward0>), tensor([5484.4673])]\n",
      "[tensor([31759.5826], grad_fn=<AddBackward0>), tensor([41661.6020])]\n",
      "[tensor([8255.7566], grad_fn=<AddBackward0>), tensor([6548.1951])]\n",
      "[tensor([6455.5076], grad_fn=<AddBackward0>), tensor([17626.2395])]\n",
      "[tensor([28854.4021], grad_fn=<AddBackward0>), tensor([37701.8768])]\n",
      "[tensor([9446.0774], grad_fn=<AddBackward0>), tensor([6571.5440])]\n",
      "[tensor([12177.3278], grad_fn=<AddBackward0>), tensor([9634.5380])]\n",
      "[tensor([9656.4336], grad_fn=<AddBackward0>), tensor([8539.6710])]\n",
      "[tensor([6539.1865], grad_fn=<AddBackward0>), tensor([3172.0180])]\n",
      "[tensor([10586.0042], grad_fn=<AddBackward0>), tensor([10107.2206])]\n",
      "[tensor([5207.9637], grad_fn=<AddBackward0>), tensor([1917.3184])]\n",
      "[tensor([13502.5713], grad_fn=<AddBackward0>), tensor([13974.4556])]\n",
      "[tensor([26984.9921], grad_fn=<AddBackward0>), tensor([34806.4677])]\n",
      "[tensor([6262.5256], grad_fn=<AddBackward0>), tensor([4337.7352])]\n",
      "[tensor([13482.4752], grad_fn=<AddBackward0>), tensor([12363.5470])]\n",
      "[tensor([35094.7307], grad_fn=<AddBackward0>), tensor([48970.2476])]\n",
      "[tensor([9519.2514], grad_fn=<AddBackward0>), tensor([7726.8540])]\n",
      "[tensor([31716.6459], grad_fn=<AddBackward0>), tensor([23887.6627])]\n",
      "[tensor([5018.9802], grad_fn=<AddBackward0>), tensor([1631.8212])]\n",
      "[tensor([8698.9389], grad_fn=<AddBackward0>), tensor([5584.3057])]\n",
      "[tensor([8692.8637], grad_fn=<AddBackward0>), tensor([7325.0482])]\n",
      "[tensor([34660.2519], grad_fn=<AddBackward0>), tensor([46130.5265])]\n",
      "[tensor([8873.4554], grad_fn=<AddBackward0>), tensor([8428.0693])]\n",
      "[tensor([14860.5110], grad_fn=<AddBackward0>), tensor([13831.1152])]\n",
      "[tensor([8378.6753], grad_fn=<AddBackward0>), tensor([7222.7863])]\n",
      "[tensor([3796.8181], grad_fn=<AddBackward0>), tensor([2709.2440])]\n",
      "[tensor([11606.6602], grad_fn=<AddBackward0>), tensor([10118.4240])]\n",
      "[tensor([10712.5079], grad_fn=<AddBackward0>), tensor([7448.4039])]\n",
      "[tensor([7454.6362], grad_fn=<AddBackward0>), tensor([5148.5526])]\n",
      "[tensor([4724.4504], grad_fn=<AddBackward0>), tensor([2362.2290])]\n",
      "[tensor([11596.3871], grad_fn=<AddBackward0>), tensor([10214.6360])]\n",
      "[tensor([6262.3058], grad_fn=<AddBackward0>), tensor([3981.9768])]\n",
      "[tensor([12972.3057], grad_fn=<AddBackward0>), tensor([11362.7550])]\n",
      "[tensor([33346.7067], grad_fn=<AddBackward0>), tensor([60021.3990])]\n",
      "[tensor([27757.5671], grad_fn=<AddBackward0>), tensor([19040.8760])]\n",
      "[tensor([4837.8961], grad_fn=<AddBackward0>), tensor([1629.8335])]\n",
      "[tensor([35491.3176], grad_fn=<AddBackward0>), tensor([48824.4500])]\n",
      "[tensor([12007.5044], grad_fn=<AddBackward0>), tensor([10736.8708])]\n",
      "[tensor([9745.1740], grad_fn=<AddBackward0>), tensor([19496.7192])]\n",
      "[tensor([8815.1961], grad_fn=<AddBackward0>), tensor([5649.7150])]\n",
      "[tensor([4009.0879], grad_fn=<AddBackward0>), tensor([2203.7359])]\n",
      "[tensor([12540.4388], grad_fn=<AddBackward0>), tensor([11842.6238])]\n",
      "[tensor([11891.2817], grad_fn=<AddBackward0>), tensor([11253.4210])]\n",
      "[tensor([10478.3055], grad_fn=<AddBackward0>), tensor([25656.5753])]\n",
      "[tensor([10979.3499], grad_fn=<AddBackward0>), tensor([8068.1850])]\n",
      "[tensor([8709.3484], grad_fn=<AddBackward0>), tensor([6664.6860])]\n",
      "[tensor([6322.0713], grad_fn=<AddBackward0>), tensor([3757.8448])]\n",
      "[tensor([8640.9160], grad_fn=<AddBackward0>), tensor([6496.8860])]\n",
      "[tensor([25375.2150], grad_fn=<AddBackward0>), tensor([15817.9857])]\n",
      "[tensor([4113.5595], grad_fn=<AddBackward0>), tensor([1621.8827])]\n",
      "[tensor([8946.0997], grad_fn=<AddBackward0>), tensor([6500.2359])]\n",
      "[tensor([6553.1407], grad_fn=<AddBackward0>), tensor([3597.5960])]\n",
      "[tensor([7232.6470], grad_fn=<AddBackward0>), tensor([5385.3379])]\n",
      "[tensor([33380.2396], grad_fn=<AddBackward0>), tensor([43578.9394])]\n",
      "[tensor([11325.4022], grad_fn=<AddBackward0>), tensor([12029.2867])]\n",
      "[tensor([29656.1025], grad_fn=<AddBackward0>), tensor([22331.5668])]\n",
      "[tensor([30374.5717], grad_fn=<AddBackward0>), tensor([40103.8900])]\n",
      "[tensor([14670.2127], grad_fn=<AddBackward0>), tensor([15161.5344])]\n",
      "[tensor([6948.1399], grad_fn=<AddBackward0>), tensor([5708.8670])]\n",
      "[tensor([9473.2280], grad_fn=<AddBackward0>), tensor([8269.0440])]\n",
      "[tensor([13263.5599], grad_fn=<AddBackward0>), tensor([11365.9520])]\n",
      "[tensor([8717.4613], grad_fn=<AddBackward0>), tensor([4762.3290])]\n",
      "[tensor([3846.9764], grad_fn=<AddBackward0>), tensor([2680.9493])]\n",
      "[tensor([9231.4926], grad_fn=<AddBackward0>), tensor([7421.1946])]\n",
      "[tensor([11860.1730], grad_fn=<AddBackward0>), tensor([11286.5387])]\n",
      "[tensor([33970.8468], grad_fn=<AddBackward0>), tensor([29141.3603])]\n",
      "[tensor([11544.6673], grad_fn=<AddBackward0>), tensor([11454.0215])]\n",
      "[tensor([33464.1996], grad_fn=<AddBackward0>), tensor([44423.8030])]\n",
      "[tensor([12657.5654], grad_fn=<AddBackward0>), tensor([10226.2842])]\n",
      "[tensor([4822.8184], grad_fn=<AddBackward0>), tensor([3046.0620])]\n",
      "[tensor([9738.8993], grad_fn=<AddBackward0>), tensor([7261.7410])]\n",
      "[tensor([7337.9716], grad_fn=<AddBackward0>), tensor([4883.8660])]\n",
      "[tensor([2733.9520], grad_fn=<AddBackward0>), tensor([1242.8160])]\n",
      "[tensor([24894.2850], grad_fn=<AddBackward0>), tensor([17468.9839])]\n",
      "[tensor([13959.1134], grad_fn=<AddBackward0>), tensor([13919.8229])]\n",
      "[tensor([9160.5522], grad_fn=<AddBackward0>), tensor([7537.1639])]\n",
      "[tensor([3644.4686], grad_fn=<AddBackward0>), tensor([2221.5644])]\n",
      "[tensor([6970.7521], grad_fn=<AddBackward0>), tensor([3201.2452])]\n",
      "[tensor([8585.4198], grad_fn=<AddBackward0>), tensor([7201.7009])]\n",
      "[tensor([8227.0564], grad_fn=<AddBackward0>), tensor([3693.4280])]\n",
      "[tensor([4478.5619], grad_fn=<AddBackward0>), tensor([1526.3120])]\n",
      "[tensor([11068.2123], grad_fn=<AddBackward0>), tensor([8124.4084])]\n",
      "[tensor([31610.1059], grad_fn=<AddBackward0>), tensor([23967.3831])]\n",
      "[tensor([8930.1609], grad_fn=<AddBackward0>), tensor([7729.6457])]\n",
      "[tensor([9058.4504], grad_fn=<AddBackward0>), tensor([8017.0612])]\n",
      "[tensor([5194.4250], grad_fn=<AddBackward0>), tensor([2020.1770])]\n",
      "[tensor([8400.0114], grad_fn=<AddBackward0>), tensor([7526.7064])]\n",
      "[tensor([6613.1281], grad_fn=<AddBackward0>), tensor([4058.7124])]\n",
      "[tensor([13291.4009], grad_fn=<AddBackward0>), tensor([12495.2908])]\n",
      "[tensor([8395.2494], grad_fn=<AddBackward0>), tensor([7077.1894])]\n",
      "[tensor([12376.3318], grad_fn=<AddBackward0>), tensor([9875.6804])]\n",
      "[tensor([4268.3013], grad_fn=<AddBackward0>), tensor([2257.4752])]\n",
      "[tensor([28637.8609], grad_fn=<AddBackward0>), tensor([43943.8761])]\n",
      "[tensor([9953.9012], grad_fn=<AddBackward0>), tensor([6781.3542])]\n",
      "[tensor([7736.4724], grad_fn=<AddBackward0>), tensor([4402.2330])]\n",
      "[tensor([11244.0989], grad_fn=<AddBackward0>), tensor([10072.0551])]\n",
      "[tensor([3615.9538], grad_fn=<AddBackward0>), tensor([2585.8506])]\n",
      "[tensor([8250.5812], grad_fn=<AddBackward0>), tensor([6128.7975])]\n",
      "[tensor([6190.7586], grad_fn=<AddBackward0>), tensor([4564.1915])]\n",
      "[tensor([4091.8916], grad_fn=<AddBackward0>), tensor([1769.5316])]\n",
      "[tensor([33902.7830], grad_fn=<AddBackward0>), tensor([47462.8940])]\n",
      "[tensor([12795.6356], grad_fn=<AddBackward0>), tensor([27322.7339])]\n",
      "[tensor([25136.2036], grad_fn=<AddBackward0>), tensor([33475.8172])]\n",
      "[tensor([34558.0297], grad_fn=<AddBackward0>), tensor([46599.1084])]\n",
      "[tensor([24799.5919], grad_fn=<AddBackward0>), tensor([15359.1045])]\n",
      "[tensor([32965.6452], grad_fn=<AddBackward0>), tensor([45702.0223])]\n",
      "[tensor([14588.8257], grad_fn=<AddBackward0>), tensor([12574.0490])]\n",
      "[tensor([3589.1697], grad_fn=<AddBackward0>), tensor([2527.8187])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_ds)):\n",
    "    print(predict_single(val_ds[i][0], val_ds[i][1], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ffcc3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46.0000,  0.0000, 35.5300,  0.0000,  1.0000])\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([31581.6337], grad_fn=<AddBackward0>), tensor([42111.6647])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(val_ds[0][0], val_ds[0][1], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef3c3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [54, 1, 34, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c09efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unknown(inputs, model):\n",
    "    pred = model.prediction(inputs)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44a061b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33417"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(predict_unknown(torch.tensor(lis, dtype=torch.float64), model).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6763ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'SavedModel/T05_HealthInsuranceCostPrediction.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e45774ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # we can save our model using pickle also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2517733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model.linear, open('SavedModel/T05_InsuranceModel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "778a1ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[  213.8172,  -272.6502,   126.6323,   295.7170, 20924.0113]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3677.2120], requires_grad=True)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0467bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[  213.8172,  -272.6502,   126.6323,   295.7170, 20924.0113]])),\n",
       "             ('linear.bias', tensor([-3677.2120]))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebd60ce8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InsuranceModel' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m33.0000\u001b[39m,  \u001b[38;5;241m0.0000\u001b[39m, \u001b[38;5;241m26.6950\u001b[39m,  \u001b[38;5;241m0.0000\u001b[39m,  \u001b[38;5;241m0.0000\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InsuranceModel' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.predict(torch.tensor([33.0000,  0.0000, 26.6950,  0.0000,  0.0000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dccc180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsuranceModel(\n",
       "  (linear): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2b188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
